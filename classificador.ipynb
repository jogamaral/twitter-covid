{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recuperando os dados que foram classificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A CUFA está em todo território nacional  e em ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a segunda onda de covid tá vindo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meus vizinhos encontraram a cura pro Covid e e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Papa Francisco disse que \"fofocar é uma praga...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nem na quarentena fiquei sem sol. Por isso ac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  sentiment\n",
       "0  A CUFA está em todo território nacional  e em ...          2\n",
       "1                   a segunda onda de covid tá vindo          2\n",
       "2  Meus vizinhos encontraram a cura pro Covid e e...          1\n",
       "3   Papa Francisco disse que \"fofocar é uma praga...          2\n",
       "4   Nem na quarentena fiquei sem sol. Por isso ac...          3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tweet_data_clf.csv',index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56\n",
       "2    40\n",
       "3     4\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df.sentiment);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver um grande desbalanceamento entre a categoria positiva e as demais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removendo Tweets duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainda que na coleta dos dados tenham sido filtrados os retweets ainda assim foram recolhidos alguns tweets duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.full_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(['full_text'], inplace=True)\n",
    "df.full_text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando teste e treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando predictors e labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = train_set.drop('sentiment',axis=1)\n",
    "classe = train_set['sentiment'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    # Remove caracteres indesejados.\n",
    "    instancia = re.sub(r\"#\\S+\", \"\", instancia)\n",
    "    instancia = re.sub(r\"@\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('\"','').replace(',','')\n",
    "    # Removendo palavras e termos frequentes que não tem relevância nos dados.\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [Preprocessing(i) for i in tweets.full_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antes: Manos por favor, COVID não tem uma cláusula assinada na qual ele infectará o indivíduo APENAS se na reunião houver mais de 5 pessoas\n",
      "Vejo gente criticando o bar até virar do avesso e reunindo com 4 pessoas que não moram c ela.\n",
      "\n",
      "Aglomeração é mais questão de chance de contágio Zé\n",
      "\n",
      "Depois: manos favor covid cláusula assinada infectará indivíduo apenas reunião 5 pessoas vejo gente criticando bar virar avesso reunindo 4 pessoas moram c aglomeração questão chance contágio zé\n"
     ]
    }
   ],
   "source": [
    "print('''Antes: {}\n",
    "\n",
    "Depois: {}'''.format(train_set.full_text.iloc[0],tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a biblioteca nltk para tokenizar os tweets. Ou seja, dividir uma string ou textos em uma lista de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['manos',\n",
       " 'favor',\n",
       " 'covid',\n",
       " 'cláusula',\n",
       " 'assinada',\n",
       " 'infectará',\n",
       " 'indivíduo',\n",
       " 'apenas',\n",
       " 'reunião',\n",
       " '5',\n",
       " 'pessoas',\n",
       " 'vejo',\n",
       " 'gente',\n",
       " 'criticando',\n",
       " 'bar',\n",
       " 'virar',\n",
       " 'avesso',\n",
       " 'reunindo',\n",
       " '4',\n",
       " 'pessoas',\n",
       " 'moram',\n",
       " 'c',\n",
       " 'aglomeração',\n",
       " 'questão',\n",
       " 'chance',\n",
       " 'contágio',\n",
       " 'zé']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "tweet_tokenizer.tokenize(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando o objeto que faz a vetorização dos dados de texto.\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o vetorizador nos dados de texto e retorna uma matriz esparsa:\n",
    "freq_tweets = vectorizer.fit_transform(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando um modelo de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treino de modelo de Machine Learning:\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando com alguns tweets do set de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Suspeita de covid more',\n",
       " '  Os casos de covid estão aumentando na Croácia. Rezando pra lenda não pegar 🙌🏽🙌🏽😭',\n",
       " 'Tem umas pessoas que eu olho os storys e fico pensando COMO que nao pegou covid ainda????????']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testes = list(test_set.iloc[1:4].full_text)\n",
    "testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras:\n",
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:  Suspeita de covid more\n",
      "           Predição: 1\n",
      "           Classificação humana: 1\n",
      "Tweet:   Os casos de covid estão aumentando na Croácia. Rezando pra lenda não pegar 🙌🏽🙌🏽😭\n",
      "           Predição: 1\n",
      "           Classificação humana: 1\n",
      "Tweet: Tem umas pessoas que eu olho os storys e fico pensando COMO que nao pegou covid ainda????????\n",
      "           Predição: 1\n",
      "           Classificação humana: 1\n"
     ]
    }
   ],
   "source": [
    "# Fazendo a classificação com o modelo treinado:\n",
    "for t, p, c in zip (testes,modelo.predict(freq_testes),test_set.iloc[1:4].sentiment):\n",
    "    # t representa o tweet e p a predição de cada tweet e c a classifição humana.\n",
    "    print ('''Tweet: {}\n",
    "           Predição: {}\n",
    "           Classificação humana: {}'''.format(t,c,p)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medindo a acurácia média do modelo:\n",
    "teste_tweets = [Preprocessing(i) for i in test_set.full_text]\n",
    "freq_teste_tweets = vectorizer.transform(teste_tweets)\n",
    "\n",
    "resultados = modelo.predict(freq_teste_tweets)\n",
    "classes = test_set.sentiment\n",
    "\n",
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição   1  2  All\n",
      "Real                \n",
      "1         10  2   12\n",
      "2          4  3    7\n",
      "3          1  0    1\n",
      "All       15  5   20\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predição'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.83      0.74        12\n",
      "           2       0.60      0.43      0.50         7\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.42      0.42      0.41        20\n",
      "weighted avg       0.61      0.65      0.62        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo:\n",
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o modelo e o vetorizador.\n",
    "filename_modelo = 'modelo_class.sav'\n",
    "pickle.dump(modelo, open(filename_modelo, 'wb'))\n",
    "\n",
    "filename_vectorizer = 'vectorizer.sav'\n",
    "pickle.dump(vectorizer, open(filename_vectorizer, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo2 = pickle.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
